#header; h1; The Lem Application

#header; h2; Why? What?
Many of us have a hobby or an art or a craft of some sort. But how to showcase it to the like-minded audience? There are many ways out there: you can write an article, you can create a video on YouTube, you can maintain a page on Wikipedia. You can even create your podcast series. Each of those approaches has its advantages and disadvantages. Some are a bit more entertaining, and the others are easier to produce. In my opinion, my craft - the art of programming - requires a unique approach.

I saw many videos about programming on YouTube. Their main disadvantage is the fact that it is quite hard to follow them. Imagine if you want to recreate or learn some specific details from the video. You will have to pause all the time, and you cannot copy the code snippets from the video. And sometimes, the details of the algorithms or complex mechanics are not explained deep enough due to the specifics of the medium.

Articles have disadvantages as well - especially the old ones. The codebase has a tendency to develop over time: bugs are fixed, ideas getting mature. If you ever read the technical articles about ancient and established products, you probably noticed what I am talking about - when the code and the text diverge significantly.

One of the approaches I liked was a so-called literate programming first time introduced by Donald Knuth. In this case, source code behaves like an open book. The author explains the codebase in proper order and with an in-depth explanation, available on the spot. I want to develop a tool that allows defining a codebase in a particular manner. Imagine, if you have an article, which can be compiled as a part of the codebase. This approach allows the code and the text to always be in sync - even if the project is being modified over time.

One more influence is the example of the C programming language. When you port a C compiler on a different hardware platform, C becomes a self-compiling assembler. You start with porting a basic functionality, then more advanced features of the language can be added on top of it while utilizing the basics. This article is something along those lines. Over time, more features will be added to the tool, and the material will be updated. This article is an example and a first use case for this tool.

I decided to call this tool Lem in the memory of one of my favorite authors - Stanislav Lem. He was a Polish writer of science fiction, philosophy and satire, and a trained physician. His books were a source of great inspiration during my childhood and early youth. If you have never read those - make yourself a favor.

Let's now start discussing the internal construction of the tool. We will dive deep into the application by explaining the foundations - the architecture of the application.

#header; h2; The CLEAN architecture of the app
Every application should have some meaningful structure behind it. This structure, commonly known as the application architecture, is the primary reference while reading and understanding the code. The common fallacy behind the application architectures is to exist just for the sake of existing. A good sign of it is when the design is too restrictive and rigid when it is hard to add use cases, which were not evident during the designing stage. To avoid this common pitfall, I am usually trying to use something as flexible as possible. The most important part of the design is to do not restrict yourself. As we all know, premature optimization is the root of all evil.

That is why I often employ a so-called CLEAN design. This approach was created and formalized by "Uncle" Bob Martin based on several other architectural designs. I like the flexibility and fundamental ideas behind this design.

The main point behind the CLEAN design is the principle of Separation of Concerns. From Wikipedia: Separation of Concerns is a design principle for separating a computer program into distinct sections so that each section addresses a separate concern. This approach allows you to represent your application as a sort of layered pie, where each layer serves to its purpose.

The main layers are Presentational Layer, Business Logic Layer, and Data Access Layer. If done from the beginning, the application can be dissected into three distinct aspects without too much hassle. That gives the ability to work abstractly and independently, brings enormous benefits during the testing stage.

Presentational Layer contains all of the logic for interacting with the platform on which your application is running. It can be something as straightforward as a Web or a mobile device, but also it can be something a bit more obscured, like a CLI style application.

Business Layer contains all of the mechanics of the application. Theoretically, it should be simple to take your Business layer and move it to the other platform like a drop-in replacement. This layer is also subdivided into specific use cases.

Data Access Layer, as the name suggests, is mostly an abstraction over the actual entities on which you operate during the application lifecycle.

I am not following the design too strictly to allow myself some slack. In my opinion, every tool can be adjusted for a job.

In the code of the application, each layer is represented by its package. "platform" for the Presentational layer, "business" is for Business Layer, and "data" is for Data Access Layer. Each package is further divided according to its own needs. For example, the Business Business Layer package contains Interactors. Each Interactor represents a set of Use Cases with similar responsibilities grouped. Data Layer is represented by Entities and Managers to access those entities. And since we aren't creating any UI, the Platform Layer is straightforward - the application class represents it.

In the next chapter, we will talk about additional auxiliary facilities, which serve as a typical boilerplate for the rest of the code.

#header; h2; Dependencies boilerplate
The key to managing the complexity of a growing project is the modularization. Modularization is a division of a system or a product into physically and functionally distinct units to allow removal and replacement. Those units have to reference each other somehow. And also we would like to allow ourselves some control and flexibility over those references. Wouldn't it be cool to be able to just remove and replace parts of the system without interrupting others?

All of that is possible with a Dependency Injection system. In software engineering, Dependency Injection is a technique, whereby one object supplies the dependencies of another object. With such system you control the creation, the destruction and a lifecycle of every component. For example you can decide if you will have only one instance of the component and therefore it will be marked as a singleton, or it will be created every time when it is required.

One more advantage of a good Dependency Injection framework is that it allows you to significantly reduce the amount of boilerplate code. Instead of dragging each dependency through the chain of constructors, you can simply inject a field through the DI on the creation stage.

This particular project uses Google's Dagger 2 to facilitate DI. One of the primary advantages of Dagger 2 over most other DI frameworks is that its strictly generated implementation - no reflexion. It means that the boilerplate code, needed for the injection, is generated during the compile time, rather being constructed during runtime through the reflexion mechanisms. That is a performance boost, of course.

First of all, in order to employ Dagger 2 for our needs, we have to specify out dependencies. This happens in a so-called Dagger 2 module. Those are application defined classes, which provides all of the necessary information about how to create and manage your application units:
#include; decl; com.blaster.platform.LemModule

The next task is to clarify the rules on how to resolve the actual dependencies. For example we can restrict a certain set of dependencies to be available only for the specified classes. Those rules can be defined in the Dagger 2 component:
#include; decl; com.blaster.platform.LemComponent

In the next chapter we will discuss a general overview of the application pipeline.

#header; h2; The pipeline overview
Let us start by briefly defining what we want to achieve with this application. My original idea was to have a tool that allows you to process the code into a readable article. Since this processing can be done every time the code is updated, we can maintain parity between the codebase and the material. The process can be dissected into distinct stages. In this chapter, we will overview those stages and define a goal for each of those.

The application starts its lifecycle, similarly to most of the JVM-based applications, with the main entry point. The main task at this stage is to handle the parameters and parse the properties of the following operation.
#include; def; com.blaster.platform.LemAppKt::main
After the main classes are created, and the parameters are consumed, we can move to the Scenario Stage.

When I am writing the articles, I usually start by outlining the table of contents. Then I follow up by adding a little bit of text for every point in the draft. In our application, this blueprint is represented by the article scenario. A scenario is a template, which sets the stage for the rest of the article. The scenario file contains text paragraphs and commands definitions to be executed. Scenario Stage starts by parsing the scenario file, and as a result, we receive a list of sections and commands which were found.

When we have a list of paragraphs and first extracted commands on hands, we can move to the next stage, which is Commands Stage. Commands stage takes the current result and applies the first commands to it. Commands can be something as simple as adding a header or changing a font, or it can be something more complicated - for example, something which will modify the structure of the article or include snippets of code to it.

In most of the cases, as a result of some commands execution, some code will be queued to be parsed. That is how we keep a permanent link between an article and a codebase. As a result of the parsing of the code, we will receive snippets and comments. It is possible to have additional commands in those comments. Those commands will follow the same procedure: after being extracted from the comments, they will be applied to a current result. You can immediately notice the recursive nature of the process.

Those steps can repeat many times. When finally, all of the commands are extracted and applied, and we have a list final list of paragraphs, we can move on to the next stage.

The final stage in the lifecycle of our application is the Printing Stage. At this stage, we take the list of paragraphs from the previous steps and convert them into an HTML page with the help of templates.

Each paragraph goes through its own type of template, which will apply different properties of the text and rendering - and will end up in the final HTML representation of the article.

So, to summarize, we start with the scenario for the article. We parse this scenario and extract the paragraphs of text and commands from it. Then we apply those commands to the current result. Some of those commands will require to parse the additional pieces of code. We will proceed by parsing the code into code snippets and comments. Comments can contain commands, as well. Extracted commands will be recursively applied to the body of the article. And finally, we will print the result all together with the help of the HTML templates.

In the next chapter, we will have a closer look at how things are parsed.

#header; h2; The Parsing Stage
In this chapter, we will see the details of the parsing of the scenario. Parsing of a modern programming language is an incredibly complex task. And this task is far outside of the reach of this article. If you need to parse multiple languages and formats, the complexity of this task can easily outweigh the gain from the project.

To avoid unnecessary complexity and to facilitate parsing, we will be using a tool called ANTLR4. What is especially good about this tool is that it comes with already available grammar for most of the modern languages. Those grammars are contributed and supported by people who are highly proficient with the languages in question.

We will employ two grammar files for our task at hand. One is for Kotlin language, and another is our custom grammar, which allows us to separate the code from the comments. what is a target of meditationIf we would like to add the support for languages, other than Kotlin in the future, we always can do this by expanding the pool of available grammar.

I will not discuss the creation of the grammars and how to use ANTLR4 because it is outside of the scope of this article. For simplicity, we can think about it as if some tool will convert the provided language constructs into the classes, available for consumption in the language of our choice - in our case - Kotlin.

Let us start with a first step - parsing of the scenario file, passed from the input arguments.
#include; def; com.blaster.business.InteractorParse::parseScenario

The scenario will produce a list of paragraphs and commands, which were identified. Let's see how the identification of the commands works.
#include; def; com.blaster.business.InteractorCommands::identifyCommands

After the commands are identified, we can finally apply them.
#include; def; com.blaster.business.InteractorCommands::applyCommands

As we already know, some commands will request to include the additional code to showcase the mechanics. Such a command will have a command name, command arguments, and the path of the code to be included. Here is the code, responsible for locating the snippets:
#include; def; com.blaster.business.InteractorLocation::locate

The author of the scenario can choose how to include the code. We can either include definitions of declarations of methods and classes. The difference is that sometimes you want to include the body of the method, and sometimes you want to mention it. Let us see how parsing of the requested definitions works.
#include; def; com.blaster.business.InteractorParse::parseDef

Parsing of the requested declarations works very similarly.
#include; def; com.blaster.business.InteractorParse::parseDecl

After the command is executed and the snippet of the code is included, the commentaries in the code can contain additional commands. In this case, we will recursively go back to the stage of the application of commands.

Finally, after all of that is done, we should have a result of the parsing stage. This result will be passed to the next step, which is the printing of the article. We will have a look at the details of the printing in the next chapter.

#header; h2; The Printing stage
The target destination of our article is an HTML file. We want to create those by parsing the codebase and executing steps required by the commands.

But how to render the actual HTML? Without a proper tool, that can be a very challenging task. For our purposes, we will use a library called FreeMarker.

Apache's FreeMarker is a template engine - a Java library to generate text output (HTML Web pages, e-mails, configuration files, source code, etc.) based on the templates and changing data. Templates are written in a FreeMarker Template Language (FTL), which is a simple specialized language. And, usually, a general-purpose programming language (like Java) is used to prepare data. Let us see how is that implemented by looking at the source code:
#include; def; com.blaster.business.InteractorPrint::printParagraphs

We are printing paragraphs by delegating pieces of the tasks to the helper methods, like this one:
#include; def; com.blaster.business.InteractorPrint::printText
Each of those will handle its piece of the overall article accordingly.

And, finally, when we have a body of the HTML page, we can wrap it into the article. The article contains header, styles, and body declaration.
#include; def; com.blaster.business.InteractorPrint::printArticle

At this point, we had a look at all steps required for processing the article - starting from the scenario and until the actual HTML output. Of course, we did not cover everything. The best place to find each and every detail is the source code. But I hope, at this point, most of the high-level concepts are explained and understood.

#header; h2; What's next?
Any craftsman can say that there is no tool, which works equally well for every job. The idea behind Lem is to be versatile enough to showcase some of the projects on which I am working.

In this article, I have shown a full pipeline of the project: from the preparation of the material to the printing stage.

The main target for Lem is to be a handy tool in explaining the Blaster - an offline renderer, on which I am currently working. I hope this article was interesting enough and will be glad to see you soon on the pages dedicated to the actual hobby - the Blaster engine - Poehali!